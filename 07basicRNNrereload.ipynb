{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x1 = np.array([[0., 1.], [1, 0], [1, 1], [0, -1], [-1, 0], [-1, -1], [-1,-1]])\n",
    "data_x2 = np.array([[1., 0.], [-1, 1], [0, -2], [2, 1], [1, -1], [2, 2], [1, 1]])\n",
    "data_xx = np.array([data_x1, data_x2])\n",
    "\n",
    "n_inputs = data_x1.shape[0]\n",
    "n_nodes = 3\n",
    "n_steps = 2\n",
    "\n",
    "state_0 = np.zeros([n_inputs, n_nodes])\n",
    "state_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sigmoind(Wx + Uy + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0, -1],\n",
       "       [ 2,  2,  1],\n",
       "       [ 1,  1,  0],\n",
       "       [ 0, -2, -1],\n",
       "       [-1,  0,  1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.array([[1, 0, -1], [2, 2, 1]])\n",
    "U = np.array([[1, 1, 0], [0, -2, -1], [-1, 0, 1]])\n",
    "b = np.array([0.5, -0.5, 1])\n",
    "\n",
    "WU = np.concatenate([W, U])\n",
    "WU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_weights = np.array([[2], [-0.5], [3]])\n",
    "output_bias = np.array([[-3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.92414182  0.81757448  0.88079708]\n",
      " [ 0.81757448  0.37754067  0.5       ]\n",
      " [ 0.97068777  0.81757448  0.73105858]\n",
      " [ 0.18242552  0.07585818  0.5       ]\n",
      " [ 0.37754067  0.37754067  0.88079708]\n",
      " [ 0.07585818  0.07585818  0.73105858]\n",
      " [ 0.07585818  0.07585818  0.73105858]]\n",
      "[[ 0.82395043  0.2295229   0.51580039]\n",
      " [ 0.86027483  0.82671081  0.95780972]\n",
      " [ 0.03695601  0.00568365  0.25227493]\n",
      " [ 0.98496796  0.82211005  0.60447392]\n",
      " [ 0.26830165  0.05327504  0.37830624]\n",
      " [ 0.99711344  0.96845057  0.83959266]\n",
      " [ 0.94504924  0.8059869   0.83959266]]\n",
      "[[ 0.74685103]\n",
      " [ 0.48659787]\n",
      " [ 0.67387503]\n",
      " [ 0.23629906]\n",
      " [ 0.551987  ]\n",
      " [ 0.33335782]\n",
      " [ 0.33335782]]\n",
      "[[ 0.52012426]\n",
      " [ 0.76505988]\n",
      " [ 0.10228358]\n",
      " [ 0.59201527]\n",
      " [ 0.20503531]\n",
      " [ 0.73667922]\n",
      " [ 0.73221368]]\n"
     ]
    }
   ],
   "source": [
    "def getState(data_x, state, WU, b):\n",
    "    data = np.concatenate([data_x, state], axis=1)\n",
    "    return sigmoid(np.matmul(data, WU) + b)\n",
    "\n",
    "def getOutput(state, output_weights, output_bias):\n",
    "    return sigmoid(np.matmul(state, output_weights) + output_bias)\n",
    "\n",
    "state_1 = getState(data_x1, state_0, WU, b)\n",
    "state_2 = getState(data_x2, state_1, WU, b)\n",
    "output_1 = getOutput(state_1, output_weights, output_bias)\n",
    "output_2 = getOutput(state_2, output_weights, output_bias)\n",
    "\n",
    "print(state_1)\n",
    "print(state_2)\n",
    "print(output_1)\n",
    "print(output_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.92414182,  0.81757448,  0.88079708],\n",
       "       [ 0.81757448,  0.37754067,  0.5       ],\n",
       "       [ 0.97068777,  0.81757448,  0.73105858],\n",
       "       [ 0.18242552,  0.07585818,  0.5       ],\n",
       "       [ 0.37754067,  0.37754067,  0.88079708],\n",
       "       [ 0.07585818,  0.07585818,  0.73105858],\n",
       "       [ 0.07585818,  0.07585818,  0.73105858]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.82395043,  0.2295229 ,  0.51580039],\n",
       "       [ 0.86027483,  0.82671081,  0.95780972],\n",
       "       [ 0.03695601,  0.00568365,  0.25227493],\n",
       "       [ 0.98496796,  0.82211005,  0.60447392],\n",
       "       [ 0.26830165,  0.05327504,  0.37830624],\n",
       "       [ 0.99711344,  0.96845057,  0.83959266],\n",
       "       [ 0.94504924,  0.8059869 ,  0.83959266]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float32, [n_steps, n_inputs, 2])\n",
    "inputs_seq = tf.unstack(inputs)\n",
    "with tf.name_scope('rec_layer'):\n",
    "    cell = tf.contrib.rnn.core_rnn_cell.BasicRNNCell(num_units=3, activation=tf.sigmoid)\n",
    "    output, state = tf.contrib.rnn.static_rnn(\n",
    "        cell=cell, inputs=inputs_seq, dtype=tf.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell_weight = [v for v in tf.trainable_variables() if v.name == 'rnn/basic_rnn_cell/weights:0'][0]\n",
    "update_weight = tf.assign(cell_weight, WU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell_bias = [v for v in tf.trainable_variables() if v.name == 'rnn/basic_rnn_cell/biases:0'][0]\n",
    "update_bias = tf.assign(cell_bias, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assigned values\n",
      "rnn/basic_rnn_cell/weights:0 [[-0.30108619 -0.80872941  0.72268444]\n",
      " [-0.78550947  0.1273762  -0.71344316]\n",
      " [ 0.45219082 -0.47534493 -0.46869576]\n",
      " [-0.03871292 -0.53958845 -0.50132215]\n",
      " [ 0.02187312  0.09094775 -0.78896606]]\n",
      "rnn/basic_rnn_cell/biases:0 [ 0.  0.  0.]\n",
      "updated\n",
      "rnn/basic_rnn_cell/weights:0 [[-0.30108619 -0.80872941  0.72268444]\n",
      " [-0.78550947  0.1273762  -0.71344316]\n",
      " [ 0.45219082 -0.47534493 -0.46869576]\n",
      " [-0.03871292 -0.53958845 -0.50132215]\n",
      " [ 0.02187312  0.09094775 -0.78896606]]\n",
      "rnn/basic_rnn_cell/biases:0 [ 0.  0.  0.]\n",
      "output1\n",
      "[[ 0.92414182  0.81757444  0.88079703]\n",
      " [ 0.81757444  0.37754068  0.5       ]\n",
      " [ 0.97068775  0.81757444  0.7310586 ]\n",
      " [ 0.18242553  0.07585818  0.5       ]\n",
      " [ 0.37754068  0.37754068  0.88079703]\n",
      " [ 0.07585818  0.07585818  0.7310586 ]\n",
      " [ 0.07585818  0.07585818  0.7310586 ]]\n",
      "output2\n",
      "[[ 0.82395041  0.22952288  0.51580036]\n",
      " [ 0.86027485  0.82671082  0.95780975]\n",
      " [ 0.03695601  0.00568365  0.25227493]\n",
      " [ 0.98496801  0.82211006  0.60447395]\n",
      " [ 0.26830167  0.05327505  0.37830624]\n",
      " [ 0.99711347  0.96845055  0.8395927 ]\n",
      " [ 0.94504929  0.80598688  0.8395927 ]]\n",
      "state\n",
      "[[ 0.82395041  0.22952288  0.51580036]\n",
      " [ 0.86027485  0.82671082  0.95780975]\n",
      " [ 0.03695601  0.00568365  0.25227493]\n",
      " [ 0.98496801  0.82211006  0.60447395]\n",
      " [ 0.26830167  0.05327505  0.37830624]\n",
      " [ 0.99711347  0.96845055  0.8395927 ]\n",
      " [ 0.94504929  0.80598688  0.8395927 ]]\n"
     ]
    }
   ],
   "source": [
    "feed_dict = {inputs: data_xx}\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    variables_names =[v.name for v in tf.trainable_variables()]\n",
    "    values = sess.run(variables_names)\n",
    "    print('assigned values')\n",
    "    for k,v in zip(variables_names, values):\n",
    "        print(k, v)\n",
    "    sess.run(update_weight)\n",
    "    sess.run(update_bias)\n",
    "    print('updated')\n",
    "    for k,v in zip(variables_names, values):\n",
    "        print(k, v)\n",
    "    out, st = sess.run((output, state), feed_dict)\n",
    "    print('output1')\n",
    "    print(out[0])\n",
    "    print('output2')\n",
    "    print(out[1])\n",
    "    print('state')\n",
    "    print(st)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
